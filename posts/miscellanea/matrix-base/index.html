<!doctype html><html lang=en><head><title>Matrix Base</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.d60808555b3afbcfaf18c23a60e08a98667faa5a60879f6703a355b38eafb832.css integrity="sha256-1ggIVVs6+8+vGMI6YOCKmGZ/qlpgh59nA6NVs46vuDI="><link rel=icon type=image/png href=/images/site/brave-logo_hu11153538395272116331.png><meta property="og:url" content="https://qingbo12.github.io/posts/miscellanea/matrix-base/"><meta property="og:site_name" content="Jinpeng's Blog"><meta property="og:title" content="Matrix Base"><meta property="og:description" content="Notes of matrix learning"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-20T16:02:00+08:00"><meta property="article:modified_time" content="2024-11-20T16:02:00+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Matrix Base"><meta name=twitter:description content="Notes of matrix learning"><meta name=description content="Notes of matrix learning"><script>theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light",theme=="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-posts kind-page" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid bg-secondary wrapper"><nav class="navbar navbar-expand-xl top-navbar shadow" id=top-navbar><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button>
<i data-feather=sidebar></i>
</button>
<a class=navbar-brand href=/><img src=/images/site/brave-logo_hu11153538395272116331.png id=logo alt=Logo>
Jinpeng's Blog</a>
<button class="navbar-toggler navbar-light" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class=nav-item><a class=nav-link href=/#education>Education</a></li><li class=nav-item><a class=nav-link href=/#projects>Projects</a></li><li class=nav-item><a class=nav-link href=/#featured-posts>Featured Posts</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=/#recent-posts>Recent Posts</a></div></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li><li class=nav-item><a class=nav-link id=note-link href=/notes>Notes</a></li><li class=nav-item><a class=nav-link href=https://toha-guides.netlify.app/posts/>Docs</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=theme-icon src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=theme-icon src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/brave-logo_hu11153538395272116331.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/brave-logo_hu11153538395272116331.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts/ data-filter=all>Posts</a></li><div class=subtree><li><a class=list-link href=/posts/building-issues/ title="Building issues">Building issues</a></li><li><a class=list-link href=/posts/introduction/ title=Introduction>Introduction</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/category/> Category</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/category/sub-category/> Sub-Category</a><ul><li><a class=list-link href=/posts/category/sub-category/rich-content/ title="Rich Content">Rich Content</a></li></ul></li></ul></li><li><a class=list-link href=/posts/markdown-sample/ title="Markdown Sample">Markdown Sample</a></li><li><a class=list-link href=/posts/shortcodes/ title="Shortcodes Sample">Shortcodes Sample</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/gcd/> Generalized Category Discovery</a><ul><li><a class=list-link href=/posts/gcd/dino/ title="DINO Read">DINO Read</a></li><li><a class=list-link href=/posts/gcd/simgcd/ title="SimGCD Read">SimGCD Read</a></li><li><a class=list-link href=/posts/gcd/transformer/ title="transformer Read">transformer Read</a></li></ul></li><li><i data-feather=minus-circle></i><a class="active list-link" href=/posts/miscellanea/> Miscellanea</a><ul class=active><li><a class=list-link href=/posts/miscellanea/c-lecture/ title="C language lecture 1">C language lecture 1</a></li><li><a class=list-link href=/posts/miscellanea/circuit/ title="Circuit Base">Circuit Base</a></li><li><a class="active list-link" href=/posts/miscellanea/matrix-base/ title="Matrix Base">Matrix Base</a></li><li><a class=list-link href=/posts/miscellanea/multimodal-fusion/ title="Multimodal-fusion research">Multimodal-fusion research</a></li><li><a class=list-link href=/posts/miscellanea/recommendation-progress/ title="Recommendation Progress">Recommendation Progress</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/wpt/> Wireless Power Transfer</a><ul><li><a class=list-link href=/posts/wpt/magmimohotspot/ title='MagMIMOHotspot Read"'>MagMIMOHotspot Read"</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/posts/miscellanea/matrix-base/images/image-miscellanea.jpg)></div><div class=page-content><div class="author-profile ms-auto align-self-lg-center"><img class=rounded-circle src=/images/author/pandas-part2_hu16066948026037313982.jpg alt="Author Image"><h5 class=author-name>Jinpeng Ma</h5><p class=text-muted>Wednesday, November 20, 2024 | 13 minutes</p></div><div class=title><h1>Matrix Base</h1></div><div class=tags><ul style=padding-left:0></ul></div><div class=post-content id=post-content><h2 id=determinant-of-matrix-product>Determinant of Matrix Product</h2><h3 id=theorem>Theorem</h3><p>Let $ A, B $ be a square matrices of order n.</p><p>Let $ det(A) $ be the determinant of $ A $.</p><p>Let $ AB $ be the matrix product of $ A $ and $ B $.</p><p>Then:</p><p>$ det(AB) = det(A)det(B) $</p><h3 id=proof>Proof</h3><p>The proof I provide is based on <a href=https://proofwiki.org/wiki/Determinant_of_Matrix_Product target=_blank rel=noopener>Determinant of Matrix Product</a></p><p>Consider two cases:</p><ol><li><p>$ A $ is singular.</p></li><li><p>$ A $ is nonsingular.</p></li></ol><p><strong>proof of case1</strong></p><p>Assume $ A $ is singular.</p><p>Then:</p><p>$$ det(A) = 0 $$</p><p><strong>Also if A is singular then so is AB.</strong></p><p>Indeed, if $ AB $ has an inverse $ C $, then:</p><p>$$ ABC = E $$</p><p>whereby $ BC $ is a right inverse of $ A $.</p><p>It follows by Left or Right Inverse of Matrix is Inverse that in that case $ BC $ is the inverse of $ A $. This contradicts the assumption.</p><p>It follows that:</p><p>$$ det(AB)=0 $$</p><p>Thus:</p><p>$$ 0 = 0 \times det(B) $$</p><p>that is:</p><p>$$ det(AB) = 0 = det(A)det(B) $$</p><p><strong>proof of case2</strong></p><p>Assume $ A $ is nonsingular.</p><p>Then $ A $ is a product of elementary row matrices, $E $.</p><p>Let $ A=E_kE_{k−1}⋯E_1 $.</p><p>So:</p><p>$$ det(AB) = det(E_kE_{k−1}⋯E_1B) $$</p><p>It remains to be shown that for any square matrix $ D $ of order n:</p><p>$$ det(ED) = det(E) det(D) $$</p><p>$ det(ED) = -|D| = det(E) det(D) $ for swap 2 rows</p><p>$ det(ED) = k|D| = det(E) det(D) $ for apply k to 1 row</p><p>$ det(ED) = |D| = det(E) det(D) $ for row(i) + k x row(j)</p><p>Then:</p><p>$ det(AB) = det(E_kE_{k−1}⋯E_1B) $</p><p>$ det(AB) = det(E_k) det(E_{k−1}⋯E_1(B)) $</p><p>$ det(AB) = αdet(B) $</p><p>and:</p><p>$ det(A) = det(E_kE_{k−1}⋯E_1I) $</p><p>$ = det(E_kE_{k−1}⋯E_1(I)) $</p><p>$ = αdet(I) $</p><p>Therefore:</p><p>$ det(AB)=det(A)det(B) $</p><h2 id=real-symmetric-matrix>Real Symmetric Matrix</h2><h3 id=theorem-all-real-eigenvalues>Theorem: all real eigenvalues</h3><p>If $ A $ is a (real) $ n \times n $ symmetric matrix, then $ A $ has n real eigenvalues (counted bytheir multiplicities). For each eigenvalue, we can find a real eigenvector associated with it.</p><h3 id=proof-1>Proof</h3><p>The proof I provide is based on <a href=https://www.math.wustl.edu/~freiwald/309orthogdiag.pdf target=_blank rel=noopener>Orthogonally Diagonalizable Matrices</a></p><p><img alt=proofofrealEigenvalues src=/posts/miscellanea/matrix-base/images/realEigenvalues.png></p><h3 id=theorem-orthogonally-diagonalizable>Theorem: orthogonally diagonalizable</h3><p>A real symmetric matrix must be orthogonally diagonalizable.</p><h3 id=proof-2>Proof</h3><p>The proof I provide is based on <a href=https://www.math.wustl.edu/~freiwald/309orthogdiag.pdf target=_blank rel=noopener>Orthogonally Diagonalizable Matrices</a></p><p>This is a proof by induction, and it uses some simple facts about partitioned matrices and change of coordinates.</p><p>This is obviously true for every $ 1 \times 1 $ matrix $ A $ if $ A = [a] $, then
$ E_1^{-1} (a) E_1 = (a) $</p><p>Assume now that every $ (n - 1) \times (n - 1) $ real symmetric matrix is orthogonally diagonalizable.</p><p>Consider an $ n \times n $ real symmetric matrix $ A $ where $ n \gt 1 $. By the preceding theorem, we can find a real eigenvalue $ \lambda $ of $ A $, together with a real eigenvector $ v_1 $. By normalizing, we can assume
$ v_1 $ is a unit eigenvector. Add vectors to extend
$ (v_1) $ to a basis for
$ R^n $ and then use the Gram Schmidt process to get an orthonormal basis for
$ R^n $:
$ (v_1, v_2, &mldr;, v_n) $.</p><p>Let</p><p>$ T_1 = (v_1, v_2, &mldr;, v_n) $.</p><p>$ T_1 $ is orthogonal.</p><p>Now look that</p><p>$$ T_1^{-1} A T_1 = T_1^{-1} (A v_1, A v_2, &mldr;, A v_n) $$</p><p>$$ T_1^{-1} A T_1 = (T_1^{-1} \lambda_1 v_1, T_1^{-1} A v_2, &mldr;, T_1^{-1} A v_n) $$</p><p>Because $ T_1^{-1} T_1 = E $, we have</p><p>$$ T_1^{-1} (v_1, v_2, &mldr;, v_n) = (\epsilon_1, \epsilon_2, &mldr;, \epsilon_n) $$</p><p>Thus, $ T_1^{-1} v_1 = \epsilon_1 $, So column 1 of
$ T_1^{-1} A T_1 $ is
$ \lambda_1 \epsilon_1 $. Suppose now that</p><p>$$
T_1^{-1} A T_1 =
\begin{pmatrix}
\lambda_1 & \alpha \\
\mathbf{0} & \beta
\end{pmatrix}
$$</p><p>$ T_1^{-1} A T_1 $ is symmetric, because</p><p>$$
(T_1^{-1} A T_1)^{\top} = (T_1^{\top} A T_1)^{\top} =
T_1^{\top} A^{\top} T_1^{\top \top} = T_1^{\top} A T_1 =
T_1^{-1} A T_1
$$</p><p>So $ \alpha = \mathbf{0} $, and
$ \beta $ is a real symmetric matrix. By the induction hypothesis, $ \beta $ is diagonalizable. Thus,
we has $ T_2 $ such that</p><p>$$
T_2^{-1} \beta T_2 = diag\{\lambda_2, \lambda_3, &mldr;, \lambda_n\}
$$</p><p>Let</p><p>$$
T = T_1
\begin{pmatrix}
1 & \mathbf{0} \\
\mathbf{0} & T_2
\end{pmatrix}
$$</p><p>$$
T^{-1} A T =
\begin{pmatrix}
1 & \mathbf{0} \\
\mathbf{0} & T_2
\end{pmatrix}^{-1}
T_1^{-1} A T_1
\begin{pmatrix}
1 & \mathbf{0} \\
\mathbf{0} & T_2
\end{pmatrix}
$$</p><p>$$
T^{-1} A T =
\begin{pmatrix}
1 & \mathbf{0} \\
\mathbf{0} & T_2^{-1}
\end{pmatrix}
\begin{pmatrix}
\lambda_1 & \mathbf{0} \\
\mathbf{0} & \beta
\end{pmatrix}
\begin{pmatrix}
1 & \mathbf{0} \\
\mathbf{0} & T_2
\end{pmatrix}
$$</p><p>$$
T^{-1} A T =
\begin{pmatrix}
\lambda_1 & \mathbf{0} \\
\mathbf{0} & T_2^{-1} \beta T_2
\end{pmatrix}
$$</p><p>$$
T^{-1} A T = diag\{\lambda_1, \lambda_2, &mldr;, \lambda_n\}
$$</p><p>Therefore, a real symmetric matrix must be orthogonally diagonalizable.</p><h3 id=theorem-r-fold-root--a---lambda-e--has-a-rank-of--n---r->Theorem: r-fold root, $ A - \lambda E $ has a rank of $ n - r $</h3><p>If $ A $ is a real symmetric matrix of order n. $ \lambda $ is an r-fold root of its characteristic polynomial</p><p>Then the matrix $ A - \lambda E $ has a rank of $ n - r $. This implies that there are exactly $ r $ linearly independent eigenvectors associated with the eigenvalue $ \lambda $.</p><h3 id=proof-3>Proof</h3><p>The proof I provide is based on <a href=https://www.zhihu.com/question/462622563/answer/1918454726 target=_blank rel=noopener>Yiwen&rsquo;s Zhihu Answer</a></p><p>Suppose that $ A&rsquo;s $ r -fold root is $ \lambda_k $.</p><p>Because $ A $ is real symmetric matrix, so we have orthogonal matrix $ P $ such that:</p><p>$$
P^{-1} A P =
\begin{pmatrix}
\lambda_1 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & \cdots & 0 \\
0 & \lambda_2 & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \blue{\lambda_{k}} & 0 & 0 & \cdots & 0 & \cdots & 0 \\
0 & 0 & 0 & 0 & 0 & \blue{\lambda_{k}} & 0 & \cdots & 0 & \cdots & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \blue{\lambda_{k}} & \cdots & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & \blue{\lambda_{k}} & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & \cdots & \lambda_n
\end{pmatrix}
$$</p><p>We don&rsquo;t care whether $ \lambda_i $ is 0 or not.</p><p>For matrix $ A - \lambda_k E $, we have:</p><p>$$
P^{-1} (A - \lambda_k E) P = P^{-1} A P - \lambda_k P^{-1} E P =
$$</p><p>$$
\varLambda - \lambda_k E =
\begin{pmatrix}
\lambda_1 - \blue{\lambda_{k}} & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & \cdots & 0 \\
0 & \lambda_2 - \blue{\lambda_{k}} & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \blue{0} & 0 & 0 & \cdots & 0 & \cdots & 0 \\
0 & 0 & 0 & 0 & 0 & \blue{0} & 0 & \cdots & 0 & \cdots & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & \blue{0} & \cdots & 0 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & \blue{0} & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & \cdots & 0 & \cdots & \lambda_n - \blue{\lambda_{k}}
\end{pmatrix}
$$</p><p>$\because \lambda_i \neq \lambda_k \Rightarrow \lambda_i - \lambda_k \neq 0, (i \neq k) $</p><p>$ \therefore rank(A - \lambda_k E) = rank(\varLambda - \lambda_k E) = n - r $</p><h2 id=vector-spaces>Vector spaces</h2><p>$ A \in M_{m,n}(\mathbf{F}) $ as a linear transformation $ x \rightarrow Ax $ from $ F^n $ to $ F^m $.
The domain of this linear transformation is $ F^n $; its range is
$ range A = \{y \in F^m : y =Ax \} $ for some $ x \in F^n $;
its null space is $ nullspace A = {x \in F^n : Ax = 0} $. The range of
$ A $ is a subspace of $ F^m $, and the null space of $ A $ is a
subspace of $ F^n $. The dimension of $ nullspace A $ is denoted by
$ nullity A $; the dimension of $ range A $ is denoted by $ rank A $.</p><h3 id=the-dimension-of--range-a--is-denoted-by--rank-a->The dimension of $ range A $ is denoted by $ rank A $</h3><p>The proof I provide is based on <a href=https://math.stackexchange.com/a/3540031 target=_blank rel=noopener>rank-of-matrix-equals-dimension-of-range</a></p><p>Suppose that we are given that the $ A \in M_{m, n}(\mathbf{F}) $
has column-rank (and therefore coincident row-rank) $ r $.
That is, the maximal set of linearly independent columns of $ A $
contains $ r $ vectors. It follows that the span of the columns of $ A $,
henceforth the column space of $ A $, is an r-dimensional subspace
of $ R^m $.</p><p>Each column of $ A $ is a vector with $ m $ entries,
so the columns live in $ F^m $. If $ n \gt m $, These columns
must be dependent, so their dimension $ r \leq m $. Hence, the column space of $ A $ is a subspace of
$ F^m $.</p><p>Let $ a_1, \cdots, a_n $ denote the columns of $ A $. Consider an
arbitrary element $ y $ inside the column space of $ A $. By definition,
this mean that there exist coefficients $ x_1, \cdots, x_n $ such that</p><p>$$
y = a_1 x_1 + a_2 x_2 + \cdots + a_n x_n
$$</p><p>Note that we can rewrite the above sum as a product. In particular,
we have</p><p>$$
y =
\begin{pmatrix}
a_1 & a_2 & \cdots & a_n
\end{pmatrix}</p><p>\begin{pmatrix}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{pmatrix}</p><p>= A x
$$</p><p>where $ x = (x_1, x_2, \cdots, x_n)^{\top} \in R^n $. So, any element
$ y $ from the column space of $ A $ is also an element of
the range of $ A $.</p><p>So the dimension of $ range A $ is denoted by $ rank A $.</p><h3 id=rank-nullity-theorem>Rank-nullity theorem</h3><p>For $ A \in M_{m, n}(\mathbf{F}) $, we have:</p><p>$$
rank(A) + nullity(A) = n
$$</p><h3 id=proof-4>Proof</h3><p>The proof I provide is based on <a href=https://www.math.purdue.edu/files/academic/courses/2010spring/MA26200/4-9.pdf target=_blank rel=noopener>The Rank-Nullity Theorem</a>.</p><p>If $ rank(A) = n $, then by the Invertible Matrix Theorem, the only solution to $ Ax = 0 $ is the trivial solution $ x = 0 $. Hence, in this case, $ nullspace(A) = {0} $, so $ nullity(A) = 0 $ and Equation holds.</p><p>Now suppose $ rank(A) = r \lt n $. In this case, there are $ n − r > 0 $ free variables in the solution to $ Ax = 0 $. Let $ t_{1}, t_{2},&mldr;,t_{n−r} $ denote these free variables (chosen as those variables not attached to a leading one in any row-echelon form of $ A $), and let $ x_1, x_2,&mldr;, x_{n−r} $ denote the solutions obtained by sequentially setting each free variable to 1 and the remaining free variables to zero. Note that $ \{ x_1, x_2,&mldr;, x_{n−r} \} $ is linearly independent. Moreover, every solution to $ Ax = 0 $ is a linear combination of $ x_1, x_2,&mldr;, x_{n−r} $:</p><p>$$
x = t_1x_1 + t_2x_2 +···+ t_{n−r}x_{n−r},
$$</p><p>which shows that $ \{ x_1, x_2,&mldr;, x_{n−r} \} $ spans $nullspace(A) $. Thus, $ \{ x_1, x_2,&mldr;, x_{n−r} \} $ is a basis for nullspace(A), so $ nullity(A) = n − r $ and Equation holds.</p><h2 id=rank>Rank</h2><h3 id=sylvester-inequality>Sylvester inequality</h3><p>If $ A \in M_{m,k} (F) $ and $ B \in M_{k,n} (F) $, then</p><p>$$
(rank A + rank B) - k \leq rank (AB)
$$</p><h3 id=proof-5>Proof</h3><p>The proof I provide is based on <a href=https://math.stackexchange.com/a/269622 target=_blank rel=noopener>Prove Sylvester rank inequality</a>.</p><p>If we prove that $ dim ker A + dim ker B \geq dim ker (AB) $.
By using the rank-nullity theorem, we can then deduce
that $ (rank A + rank B) - k \leq rank (AB) $.</p><p>Firstly, we show that $ kerB \subseteq ker(AB) $.</p><p>Any $ x \in kerB $, we have:</p><p>$$ B x = 0 $$</p><p>Now, applying the matrix $ A $ to both sides of this equation:</p><p>$$ A B x = A 0 = 0 \Rightarrow x \in ker(AB) $$</p><p>Thus $ kerB \subseteq ker(AB) $.</p><p>Then we show that $ dim ker A + dim ker B \geq dim ker (AB) $.</p><p>Let $ \beta = \{\alpha_1,…,\alpha_r\} $ be a basis for $ kerB $.
Because $ kerB \subseteq ker(AB) $, so we can extend $ \beta $ to
a basis for $ ker(AB) $. Suppose $ \{\alpha_1, \cdots, \alpha_r,
\alpha_{r+1}, \cdots, \alpha_n \} $ be basis for $ ker(AB) $. Since
$ \alpha_{i + 1}, \cdots, \alpha_n \notin kerB $, we have that
$ B \alpha_i \neq 0 $ for $ i \in \{ r \lt i \lt n + 1 \} $.</p><p>We show that $ \{B \alpha_{r+1}, \cdots, B \alpha_n \} $ is
linear independent. If we can show that, then we would have $ dim ker A \geq n - r $.
(Note: $ dim ker A \neq dim ker (AB) $, Because $ B \alpha_i = 0 $, for $ i \in \{ 1 \leq i \leq r \} $,
if we add $ B \alpha_1 $ to $ \{B \alpha_{r+1}, \cdots, B \alpha_n \} $,
we would have $ \{ B \alpha_1, B \alpha_{r+1}, \cdots, B \alpha_n \} $ is linear dependent.
So we could only say $ dim ker A \geq n - r $.)</p><p>Assume that there exist scalars $ \lambda_1, \cdots, \lambda_n $,
not all zero, such that $ \sum_{i = r + 1}^n \lambda_i B \alpha_i = 0 $.
Since $ B $ is linear, we have $ B \sum_{i = r + 1}^n \lambda_i \alpha_i = 0 $,
so that $ \sum_{i = r + 1}^n \lambda_i \alpha_i $ belongs to the kernel
of $ B $. On other hand, we already know that $ \beta = \{\alpha_1,…,\alpha_r\} $ be a basis for $ kerB $.
Next since the set $ \{\alpha_1, \cdots, \alpha_r, \alpha_{r+1}, \cdots,
\alpha_n \} $ is an independent set, we infer that $ \lambda_i $ must be
zero for all $ i = r + 1, \cdots, n $.</p><p>Now one can see that</p><p>$$
dim ker A + dim ker B \geq n - r + r = n \Rightarrow dim ker A + dim ker B \geq dim ker (AB)
$$</p><p>Using the rank-nullity theorem, we have</p><p>$$
k - rank A + n - rank B \geq n - rank (AB) \Rightarrow (rank A + rank B) - k \leq rank (AB)
$$</p></div><div class="row ps-3 pe-3"><div class="col-md-6 share-buttons"></div><div class="col-md-6 btn-improve-page"><a href=https://github.com/qingbo12/qingbo12.github.io/edit/main/content/posts/Miscellanea/matrix-base/index.md title="Improve this page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>
Improve this page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/miscellanea/circuit/ title="Circuit Base" class="btn filled-button"><div><i class="fas fa-chevron-circle-left"></i> Prev</div><div class=next-prev-text>Circuit Base</div></a></div><div class="col-md-6 next-article"><a href=/posts/miscellanea/multimodal-fusion/ title="Multimodal-fusion research" class="btn filled-button"><div>Next <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Multimodal-fusion research</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn type=button data-bs-toggle=tooltip data-bs-placement=left title="Scroll to top"><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center ps-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#determinant-of-matrix-product>Determinant of Matrix Product</a><ul><li><a href=#theorem>Theorem</a></li><li><a href=#proof>Proof</a></li></ul></li><li><a href=#real-symmetric-matrix>Real Symmetric Matrix</a><ul><li><a href=#theorem-all-real-eigenvalues>Theorem: all real eigenvalues</a></li><li><a href=#proof-1>Proof</a></li><li><a href=#theorem-orthogonally-diagonalizable>Theorem: orthogonally diagonalizable</a></li><li><a href=#proof-2>Proof</a></li><li><a href=#theorem-r-fold-root--a---lambda-e--has-a-rank-of--n---r->Theorem: r-fold root, $ A - \lambda E $ has a rank of $ n - r $</a></li><li><a href=#proof-3>Proof</a></li></ul></li><li><a href=#vector-spaces>Vector spaces</a><ul><li><a href=#the-dimension-of--range-a--is-denoted-by--rank-a->The dimension of $ range A $ is denoted by $ rank A $</a></li><li><a href=#rank-nullity-theorem>Rank-nullity theorem</a></li><li><a href=#proof-4>Proof</a></li></ul></li><li><a href=#rank>Rank</a><ul><li><a href=#sylvester-inequality>Sylvester inequality</a></li><li><a href=#proof-5>Proof</a></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://qingbo12.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://qingbo12.github.io/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://qingbo12.github.io/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://qingbo12.github.io/#featured-posts>Featured Posts</a></li><li class=nav-item><a class=smooth-scroll href=https://qingbo12.github.io/#recent-posts>Recent Posts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:qingbo12@gmail.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>qingbo12@gmail.com</span></a></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>Liability Notice:</strong> This theme is under MIT license. So, you can use it for non-commercial, commercial, or private uses. You can modify or distribute the theme without requiring any permission from the theme author. However, the theme author does not provide any warranty or takes any liability for any issue with the theme.</p></div><hr><div class=container><div class="row text-start"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu16779671404603505019.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2024 Copyright.</div><div class="col-md-4 text-end"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.aa1b29568827d862abc07cd2a25fa9f3f1dad96fd8fe2a012bccae2de39367fc.js integrity="sha256-qhspVogn2GKrwHzSol+p8/Ha2W/Y/ioBK8yuLeOTZ/w=" defer></script></body></html>